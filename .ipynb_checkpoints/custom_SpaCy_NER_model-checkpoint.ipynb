{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nOD9x2lAC39q",
        "outputId": "8718f16d-0027-448e-c1dc-f1420db969ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: docx2txt in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (0.8)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: fitz in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (0.0.1.dev2)\n",
            "Requirement already satisfied: configobj in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (5.0.9)\n",
            "Requirement already satisfied: configparser in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (7.2.0)\n",
            "Requirement already satisfied: httplib2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (0.30.0)\n",
            "Requirement already satisfied: nibabel in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (5.3.2)\n",
            "Requirement already satisfied: nipype in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.10.0)\n",
            "Requirement already satisfied: numpy in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.26.4)\n",
            "Requirement already satisfied: pandas in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (2.3.2)\n",
            "Requirement already satisfied: pyxnat in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.6.3)\n",
            "Requirement already satisfied: scipy in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.16.1)\n",
            "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from httplib2->fitz) (3.2.3)\n",
            "Requirement already satisfied: importlib-resources>=5.12 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nibabel->fitz) (6.5.2)\n",
            "Requirement already satisfied: packaging>=20 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nibabel->fitz) (25.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nibabel->fitz) (4.15.0)\n",
            "Requirement already satisfied: click>=6.6.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (8.2.1)\n",
            "Requirement already satisfied: networkx>=2.5 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (3.5)\n",
            "Requirement already satisfied: prov>=1.5.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (2.1.1)\n",
            "Requirement already satisfied: pydot>=1.2.3 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (2.9.0.post0)\n",
            "Requirement already satisfied: rdflib>=5.0.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (7.1.4)\n",
            "Requirement already satisfied: simplejson>=3.8.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (3.20.1)\n",
            "Requirement already satisfied: traits>=6.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (7.0.2)\n",
            "Requirement already satisfied: filelock>=3.0.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (3.19.1)\n",
            "Requirement already satisfied: acres in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (0.5.0)\n",
            "Requirement already satisfied: etelemetry>=0.3.1 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (0.3.1)\n",
            "Requirement already satisfied: looseversion!=1.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (1.3.0)\n",
            "Requirement already satisfied: puremagic in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (1.30)\n",
            "Requirement already satisfied: colorama in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from click>=6.6.0->nipype->fitz) (0.4.6)\n",
            "Requirement already satisfied: requests in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (2.32.5)\n",
            "Requirement already satisfied: ci-info>=0.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
            "Requirement already satisfied: six>=1.5 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
            "Requirement already satisfied: lxml>=4.3 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pyxnat->fitz) (6.0.1)\n",
            "Requirement already satisfied: pathlib>=1.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pyxnat->fitz) (1.0.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2025.8.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install docx2txt\n",
        "%pip install fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd70c71d",
        "outputId": "0ea4d5a6-000f-43c6-cbfa-f8e8512896c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyMuPDF in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade PyMuPDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "2tLKHmoJ7uEj"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "from spacy.training.example import Example\n",
        "import pandas as pd\n",
        "import json\n",
        "from pathlib import Path\n",
        "import random\n",
        "import os\n",
        "import docx2txt\n",
        "import fitz  # PyMuPDF for PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGENzeDUJBrX",
        "outputId": "8eafd50a-cd27-4b9d-ce96-0a628f2de95b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "spacy :  3.7.2\n",
            "pandas :  2.3.2\n",
            "json :  2.0.9\n",
            "fitz :  1.26.4\n"
          ]
        }
      ],
      "source": [
        "print(\"spacy : \",spacy.__version__ )\n",
        "print(\"pandas : \",pd.__version__ )\n",
        "print(\"json : \",json.__version__ )\n",
        "print(\"fitz : \",fitz.__version__ )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openpyxl\n",
            "  Using cached openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting et-xmlfile (from openpyxl)\n",
            "  Using cached et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Using cached openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "Using cached et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: et-xmlfile, openpyxl\n",
            "\n",
            "   ---------------------------------------- 0/2 [et-xmlfile]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   -------------------- ------------------- 1/2 [openpyxl]\n",
            "   ---------------------------------------- 2/2 [openpyxl]\n",
            "\n",
            "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openpyxl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "CjVI_y7476KC"
      },
      "outputs": [],
      "source": [
        "# 1. Load Excel\n",
        "\n",
        "df = pd.read_excel(r\"D:\\CybaemTech\\Projects\\name_extraction_model\\extract_text.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "RoV9s0uL8Rt1"
      },
      "outputs": [],
      "source": [
        "# Assume the column is called \"data\" (update with your actual column name)\n",
        "TRAIN_DATA = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvOUPSbt8Un6",
        "outputId": "5c8aac30-84e7-482a-bbb9-cbb4c77bf5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
            " Training examples prepared: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\abc\\AppData\\Local\\Temp\\ipykernel_11288\\4226686023.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  data_dict = json.loads(row[0])  # assumes JSON is in first column\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for _, row in df.iterrows():\n",
        "    try:\n",
        "        data_dict = json.loads(row[0])  # assumes JSON is in first column\n",
        "        name = str(data_dict[\"name\"]).strip()\n",
        "        text = str(data_dict[\"resume_text\"]).strip()\n",
        "\n",
        "        start = text.lower().find(name.lower())\n",
        "        if start != -1:\n",
        "            end = start + len(name)\n",
        "            TRAIN_DATA.append((text, {\"entities\": [(start, end, \"NAME\")]}))\n",
        "        else:\n",
        "            print(f\" Name '{name}' not found in resume text. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error parsing row: {e}\")\n",
        "\n",
        "print(f\" Training examples prepared: {len(TRAIN_DATA)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "802fc6ed",
        "outputId": "07856329-ec4e-4b16-8b0e-0d8e90926445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object\n",
            "0          ABHIJEET PATHAK\n",
            "1      Ade Nikhil Nilkanth\n",
            "2              Adnan Ahmad\n",
            "3             Ajay A. Wagh\n",
            "4    AJEET KUMAR PRAJAPATI\n",
            "Name: Name, dtype: object\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Inspect the first column of the DataFrame\n",
        "print(df.iloc[:, 0].dtype)\n",
        "print(df.iloc[:, 0].head())\n",
        "print(df.iloc[:, 0].isnull().sum())\n",
        "print(df[df.iloc[:, 0] == ''].shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1eb2ddb",
        "outputId": "424cf192-a5d8-48dd-caa4-d9dac21fcf00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object\n",
            "0    ABHIJEET PATHAK Pune, India |+91-7694070046|ab...\n",
            "1    Nikhil Nilkanth Latkar +91-8600395778 | E-mail...\n",
            "2    Adnan Ahmad Email: adnanreboot@gmail.com | Pho...\n",
            "3    CURRICULUM VITAE Ajay A. Wagh Address : Plot n...\n",
            "4    AJEET KUMAR PRAJAPATI C O N S U L T A N T http...\n",
            "Name: Content, dtype: object\n",
            "0\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "# Inspect the 'Content' column of the DataFrame\n",
        "print(df['Content'].dtype)\n",
        "print(df['Content'].head())\n",
        "print(df['Content'].isnull().sum())\n",
        "print(df[df['Content'] == ''].shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b6a0fee",
        "outputId": "c9e31dc0-8610-44b7-f8fc-b65299b16168"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Name 'Ade Nikhil Nilkanth' not found in resume text for row 1. Skipping.\n",
            " Name 'Rahul Resume' not found in resume text for row 38. Skipping.\n",
            " Name 'Rutuja_s D.txt' not found in resume text for row 49. Skipping.\n",
            "Total training examples: 60\n"
          ]
        }
      ],
      "source": [
        "TRAIN_DATA = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "    try:\n",
        "        name = str(row['Name']).strip()\n",
        "        text = str(row['Content']).strip()\n",
        "\n",
        "        # Case-insensitive search\n",
        "        start = text.lower().find(name.lower())\n",
        "        if start != -1:\n",
        "            end = start + len(name)\n",
        "            TRAIN_DATA.append((text, {\"entities\": [(start, end, \"NAME\")]}))\n",
        "        else:\n",
        "            print(f\" Name '{name}' not found in resume text for row {index}. Skipping.\")\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing row {index}: {e}\")\n",
        "\n",
        "print(f\"Total training examples: {len(TRAIN_DATA)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQmqyqzdB3Aa",
        "outputId": "08370e0a-6198-4296-a675-9fd5f4a41b83"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "d:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Configuring VPN and troubleshooting VPN issues (Gl...\" with entities \"[(1310, 1324, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n",
            "d:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Bangalore,Karnataka India.PIN-560036EDAGOTTI HARIN...\" with entities \"[(36, 53, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iteration 0 Losses: {'ner': 3255.572797725193}\n",
            "Iteration 1 Losses: {'ner': 50.83849529480947}\n",
            "Iteration 2 Losses: {'ner': 33.15297043781811}\n",
            "Iteration 3 Losses: {'ner': 25.790587884414123}\n",
            "Iteration 4 Losses: {'ner': 7.604171869736608}\n",
            "Iteration 5 Losses: {'ner': 4.68317306165073}\n",
            "Iteration 6 Losses: {'ner': 2.7494387871617954}\n",
            "Iteration 7 Losses: {'ner': 1.5701500602516827}\n",
            "Iteration 8 Losses: {'ner': 0.6750605284893967}\n",
            "Iteration 9 Losses: {'ner': 4.330675196141078e-06}\n",
            "Iteration 10 Losses: {'ner': 5.215279136158382e-07}\n",
            "Iteration 11 Losses: {'ner': 1.938700633170307e-06}\n",
            "Iteration 12 Losses: {'ner': 1.329422616176867e-06}\n",
            "Iteration 13 Losses: {'ner': 9.983240684470717e-07}\n",
            "Iteration 14 Losses: {'ner': 5.065351271330892e-08}\n",
            "Iteration 15 Losses: {'ner': 3.0251517914302354e-07}\n",
            "Iteration 16 Losses: {'ner': 2.0121216962532687e-08}\n",
            "Iteration 17 Losses: {'ner': 1.1464883346245124e-07}\n",
            "Iteration 18 Losses: {'ner': 3.4865273712177645e-08}\n",
            "Iteration 19 Losses: {'ner': 1.3621087703683993e-07}\n"
          ]
        }
      ],
      "source": [
        "# 2. Train SpaCy Model\n",
        "\n",
        "nlp = spacy.blank(\"en\")\n",
        "ner = nlp.add_pipe(\"ner\")\n",
        "ner.add_label(\"NAME\")\n",
        "\n",
        "optimizer = nlp.begin_training()\n",
        "\n",
        "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
        "with nlp.disable_pipes(*other_pipes):\n",
        "    for itn in range(20):  # training iterations\n",
        "        random.shuffle(TRAIN_DATA)\n",
        "        losses = {}\n",
        "        batches = spacy.util.minibatch(TRAIN_DATA, size=2)\n",
        "        for batch in batches:\n",
        "            for text, annotations in batch:\n",
        "                doc = nlp.make_doc(text)\n",
        "                example = Example.from_dict(doc, annotations)\n",
        "                nlp.update([example], sgd=optimizer, losses=losses)\n",
        "        print(f\"Iteration {itn} Losses: {losses}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxsS3j6VB9fP",
        "outputId": "3028b999-25c9-468e-dde5-88a5ac65778f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Model saved to D:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\n"
          ]
        }
      ],
      "source": [
        "# Save trained model\n",
        "model_dir = Path(\"Name_extraction_model\")\n",
        "nlp.to_disk(model_dir)\n",
        "print(f\" Model saved to {model_dir.resolve()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "HSYs6e50CFiJ"
      },
      "outputs": [],
      "source": [
        "# 3. Inference Functions\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    text = docx2txt.process(docx_path)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_name_from_resume(file_path, model_path=\"custom_name_ner\"):\n",
        "    nlp_model = spacy.load(model_path)\n",
        "\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        resume_text = extract_text_from_pdf(file_path)\n",
        "    elif ext == \".docx\":\n",
        "        resume_text = extract_text_from_docx(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Only .pdf and .docx files are supported\")\n",
        "\n",
        "    doc = nlp_model(resume_text)\n",
        "    names = [ent.text for ent in doc.ents if ent.label_ == \"NAME\"]\n",
        "\n",
        "    return names[0] if names else None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vwqo_pZF7T0",
        "outputId": "6481fd4f-3877-4285-b602-8be92ba11c96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation Results:\n",
            "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'NAME': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'speed': 20023.138562365326}\n",
            "  Precision: 1.0\n",
            "  Recall: 1.0\n",
            "  F-score: 1.0\n"
          ]
        }
      ],
      "source": [
        "# 4. Evaluate the Model\n",
        "\n",
        "# Create a list of Example objects\n",
        "examples = []\n",
        "for text, annotations in TRAIN_DATA:\n",
        "    doc = nlp.make_doc(text)\n",
        "    example = Example.from_dict(doc, annotations)\n",
        "    examples.append(example)\n",
        "\n",
        "# Evaluate the model\n",
        "results = nlp.evaluate(examples) # Use the list of Example objects for evaluation\n",
        "print(\"Evaluation Results:\")\n",
        "print(results)\n",
        "\n",
        "# You can access specific metrics like:\n",
        "print(f\"  Precision: {results['token_p']}\")\n",
        "print(f\"  Recall: {results['token_r']}\")\n",
        "print(f\"  F-score: {results['token_f']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "PQDU92dUGnIF",
        "outputId": "fe80955d-e381-411f-cee1-f4dbbf24f5e8"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[36]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgoogle\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcolab\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m files\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocx2txt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'google'"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "import docx2txt\n",
        "import fitz  # PyMuPDF for PDF\n",
        "import spacy\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with fitz.open(pdf_path) as doc:\n",
        "        for page in doc:\n",
        "            text += page.get_text()\n",
        "    return text.strip()\n",
        "\n",
        "def extract_text_from_docx(docx_path):\n",
        "    text = docx2txt.process(docx_path)\n",
        "    return text.strip()\n",
        "\n",
        "def extract_name_from_resume(file_path, model_path=\"custom_name_ner\"):\n",
        "    nlp_model = spacy.load(model_path)\n",
        "\n",
        "    ext = os.path.splitext(file_path)[-1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        resume_text = extract_text_from_pdf(file_path)\n",
        "    elif ext == \".docx\":\n",
        "        resume_text = extract_text_from_docx(file_path)\n",
        "    else:\n",
        "        raise ValueError(\"Only .pdf and .docx files are supported\")\n",
        "\n",
        "    doc = nlp_model(resume_text)\n",
        "    names = [ent.text for ent in doc.ents if ent.label_ == \"NAME\"]\n",
        "\n",
        "    return names[0] if names else None\n",
        "\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "test_resume = list(uploaded.keys())[0]\n",
        "extracted_name = extract_name_from_resume(test_resume, model_path=\"Name_extraction_model\")\n",
        "\n",
        "if extracted_name:\n",
        "    print(f\" Extracted Name: {extracted_name}\")\n",
        "else:\n",
        "    print(\" No name detected in the resume\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-f2n7V5L44N"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "joblib.dump(nlp, \"name_extraction_model.pkl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"model saved as name_extraction_model.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "name_extraction_model",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
