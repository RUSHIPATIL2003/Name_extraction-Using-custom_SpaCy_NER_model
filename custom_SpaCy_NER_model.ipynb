{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nOD9x2lAC39q",
    "outputId": "8718f16d-0027-448e-c1dc-f1420db969ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: docx2txt in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (0.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: fitz in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (5.0.9)\n",
      "Requirement already satisfied: configparser in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (7.2.0)\n",
      "Requirement already satisfied: httplib2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (0.30.0)\n",
      "Requirement already satisfied: nibabel in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (5.3.2)\n",
      "Requirement already satisfied: nipype in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.10.0)\n",
      "Requirement already satisfied: numpy in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.26.4)\n",
      "Requirement already satisfied: pandas in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (2.3.2)\n",
      "Requirement already satisfied: pyxnat in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.6.3)\n",
      "Requirement already satisfied: scipy in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from fitz) (1.16.1)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from httplib2->fitz) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=5.12 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nibabel->fitz) (6.5.2)\n",
      "Requirement already satisfied: packaging>=20 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nibabel->fitz) (25.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nibabel->fitz) (4.15.0)\n",
      "Requirement already satisfied: click>=6.6.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (8.2.1)\n",
      "Requirement already satisfied: networkx>=2.5 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (3.5)\n",
      "Requirement already satisfied: prov>=1.5.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (2.1.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (4.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (7.1.4)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (7.0.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (3.19.1)\n",
      "Requirement already satisfied: acres in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (0.5.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: puremagic in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from nipype->fitz) (1.30)\n",
      "Requirement already satisfied: colorama in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from click>=6.6.0->nipype->fitz) (0.4.6)\n",
      "Requirement already satisfied: requests in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (2.32.5)\n",
      "Requirement already satisfied: ci-info>=0.2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: six>=1.5 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pandas->fitz) (2025.2)\n",
      "Requirement already satisfied: lxml>=4.3 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pyxnat->fitz) (6.0.1)\n",
      "Requirement already satisfied: pathlib>=1.0 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from requests->etelemetry>=0.3.1->nipype->fitz) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install docx2txt\n",
    "%pip install fitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd70c71d",
    "outputId": "0ea4d5a6-000f-43c6-cbfa-f8e8512896c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyMuPDF in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2tLKHmoJ7uEj"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.training.example import Example\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import os\n",
    "import docx2txt\n",
    "import fitz  # PyMuPDF for PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGENzeDUJBrX",
    "outputId": "8eafd50a-cd27-4b9d-ce96-0a628f2de95b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spacy :  3.7.2\n",
      "pandas :  2.3.2\n",
      "json :  2.0.9\n",
      "fitz :  1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(\"spacy : \",spacy.__version__ )\n",
    "print(\"pandas : \",pd.__version__ )\n",
    "print(\"json : \",json.__version__ )\n",
    "print(\"fitz : \",fitz.__version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in d:\\cybaemtech\\projects\\name_extraction_model\\name_extraction_model\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "CjVI_y7476KC"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABHIJEET PATHAK</td>\n",
       "      <td>ABHIJEET PATHAK Pune, India |+91-7694070046|ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ade Nikhil Nilkanth</td>\n",
       "      <td>Nikhil Nilkanth Latkar +91-8600395778 | E-mail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adnan Ahmad</td>\n",
       "      <td>Adnan Ahmad Email: adnanreboot@gmail.com | Pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ajay A. Wagh</td>\n",
       "      <td>CURRICULUM VITAE Ajay A. Wagh Address : Plot n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AJEET KUMAR PRAJAPATI</td>\n",
       "      <td>AJEET KUMAR PRAJAPATI C O N S U L T A N T http...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name                                            Content\n",
       "0        ABHIJEET PATHAK  ABHIJEET PATHAK Pune, India |+91-7694070046|ab...\n",
       "1    Ade Nikhil Nilkanth  Nikhil Nilkanth Latkar +91-8600395778 | E-mail...\n",
       "2            Adnan Ahmad  Adnan Ahmad Email: adnanreboot@gmail.com | Pho...\n",
       "3           Ajay A. Wagh  CURRICULUM VITAE Ajay A. Wagh Address : Plot n...\n",
       "4  AJEET KUMAR PRAJAPATI  AJEET KUMAR PRAJAPATI C O N S U L T A N T http..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load Excel\n",
    "\n",
    "df = pd.read_excel(r\"D:\\CybaemTech\\Projects\\name_extraction_model\\extract_text_dataset.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RoV9s0uL8Rt1"
   },
   "outputs": [],
   "source": [
    "# Assume the column is called \"data\" (update with your actual column name)\n",
    "TRAIN_DATA = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bvOUPSbt8Un6",
    "outputId": "5c8aac30-84e7-482a-bbb9-cbb4c77bf5b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Error parsing row: Expecting value: line 1 column 1 (char 0)\n",
      " Training examples prepared: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abc\\AppData\\Local\\Temp\\ipykernel_6776\\4226686023.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  data_dict = json.loads(row[0])  # assumes JSON is in first column\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for _, row in df.iterrows():\n",
    "    try:\n",
    "        data_dict = json.loads(row[0])  # assumes JSON is in first column\n",
    "        name = str(data_dict[\"name\"]).strip()\n",
    "        text = str(data_dict[\"resume_text\"]).strip()\n",
    "\n",
    "        start = text.lower().find(name.lower())\n",
    "        if start != -1:\n",
    "            end = start + len(name)\n",
    "            TRAIN_DATA.append((text, {\"entities\": [(start, end, \"NAME\")]}))\n",
    "        else:\n",
    "            print(f\" Name '{name}' not found in resume text. Skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error parsing row: {e}\")\n",
    "\n",
    "print(f\" Training examples prepared: {len(TRAIN_DATA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "802fc6ed",
    "outputId": "07856329-ec4e-4b16-8b0e-0d8e90926445"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0          ABHIJEET PATHAK\n",
      "1      Ade Nikhil Nilkanth\n",
      "2              Adnan Ahmad\n",
      "3             Ajay A. Wagh\n",
      "4    AJEET KUMAR PRAJAPATI\n",
      "Name: Name, dtype: object\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the first column of the DataFrame\n",
    "print(df.iloc[:, 0].dtype)\n",
    "print(df.iloc[:, 0].head())\n",
    "print(df.iloc[:, 0].isnull().sum())\n",
    "print(df[df.iloc[:, 0] == ''].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f1eb2ddb",
    "outputId": "424cf192-a5d8-48dd-caa4-d9dac21fcf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0    ABHIJEET PATHAK Pune, India |+91-7694070046|ab...\n",
      "1    Nikhil Nilkanth Latkar +91-8600395778 | E-mail...\n",
      "2    Adnan Ahmad Email: adnanreboot@gmail.com | Pho...\n",
      "3    CURRICULUM VITAE Ajay A. Wagh Address : Plot n...\n",
      "4    AJEET KUMAR PRAJAPATI C O N S U L T A N T http...\n",
      "Name: Content, dtype: object\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Inspect the 'Content' column of the DataFrame\n",
    "print(df['Content'].dtype)\n",
    "print(df['Content'].head())\n",
    "print(df['Content'].isnull().sum())\n",
    "print(df[df['Content'] == ''].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9b6a0fee",
    "outputId": "c9e31dc0-8610-44b7-f8fc-b65299b16168"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name 'Ade Nikhil Nilkanth' not found in resume text for row 1. Skipping.\n",
      " Name 'Rahul Resume' not found in resume text for row 38. Skipping.\n",
      " Name 'Rutuja_s D.txt' not found in resume text for row 49. Skipping.\n",
      "Total training examples: 60\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DATA = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        name = str(row['Name']).strip()\n",
    "        text = str(row['Content']).strip()\n",
    "\n",
    "        # Case-insensitive search\n",
    "        start = text.lower().find(name.lower())\n",
    "        if start != -1:\n",
    "            end = start + len(name)\n",
    "            TRAIN_DATA.append((text, {\"entities\": [(start, end, \"NAME\")]}))\n",
    "        else:\n",
    "            print(f\" Name '{name}' not found in resume text for row {index}. Skipping.\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error processing row {index}: {e}\")\n",
    "\n",
    "print(f\"Total training examples: {len(TRAIN_DATA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQmqyqzdB3Aa",
    "outputId": "08370e0a-6198-4296-a675-9fd5f4a41b83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Bangalore,Karnataka India.PIN-560036EDAGOTTI HARIN...\" with entities \"[(36, 53, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Configuring VPN and troubleshooting VPN issues (Gl...\" with entities \"[(1310, 1324, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 Losses: {'ner': 4008.8232962120355}\n",
      "Iteration 1 Losses: {'ner': 45.25722351059748}\n",
      "Iteration 2 Losses: {'ner': 265.78023728455145}\n",
      "Iteration 3 Losses: {'ner': 29.015717362047983}\n",
      "Iteration 4 Losses: {'ner': 3.9930283060287963}\n",
      "Iteration 5 Losses: {'ner': 0.020256090898646394}\n",
      "Iteration 6 Losses: {'ner': 0.0011082847561785351}\n",
      "Iteration 7 Losses: {'ner': 1.7835934339853418e-07}\n",
      "Iteration 8 Losses: {'ner': 1.6102974870326884e-07}\n",
      "Iteration 9 Losses: {'ner': 1.514064158558074e-07}\n",
      "Iteration 10 Losses: {'ner': 1.010971263653254e-06}\n",
      "Iteration 11 Losses: {'ner': 1.7334639236464157e-05}\n",
      "Iteration 12 Losses: {'ner': 6.80791028824181e-08}\n",
      "Iteration 13 Losses: {'ner': 5.823842182343908e-07}\n",
      "Iteration 14 Losses: {'ner': 7.760505054540291e-08}\n",
      "Iteration 15 Losses: {'ner': 2.535499066273259e-07}\n",
      "Iteration 16 Losses: {'ner': 4.825583891137131e-08}\n",
      "Iteration 17 Losses: {'ner': 1.4212730606633098e-07}\n",
      "Iteration 18 Losses: {'ner': 3.5198532287412597e-07}\n",
      "Iteration 19 Losses: {'ner': 4.934458594472835e-08}\n"
     ]
    }
   ],
   "source": [
    "# 2. Train SpaCy Model\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "ner = nlp.add_pipe(\"ner\")\n",
    "ner.add_label(\"NAME\")\n",
    "\n",
    "optimizer = nlp.begin_training()\n",
    "\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n",
    "with nlp.disable_pipes(*other_pipes):\n",
    "    for itn in range(20):  # training iterations\n",
    "        random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        batches = spacy.util.minibatch(TRAIN_DATA, size=2)\n",
    "        for batch in batches:\n",
    "            for text, annotations in batch:\n",
    "                doc = nlp.make_doc(text)\n",
    "                example = Example.from_dict(doc, annotations)\n",
    "                nlp.update([example], sgd=optimizer, losses=losses)\n",
    "        print(f\"Iteration {itn} Losses: {losses}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZxsS3j6VB9fP",
    "outputId": "3028b999-25c9-468e-dde5-88a5ac65778f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model saved to D:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\n"
     ]
    }
   ],
   "source": [
    "# Save trained model\n",
    "model_dir = Path(\"Name_extraction_model\")\n",
    "nlp.to_disk(model_dir)\n",
    "print(f\" Model saved to {model_dir.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HSYs6e50CFiJ"
   },
   "outputs": [],
   "source": [
    "# 3. Inference Functions\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:\n",
    "        for page in doc:\n",
    "            text += page.get_text()\n",
    "    return text.strip()\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    text = docx2txt.process(docx_path)\n",
    "    return text.strip()\n",
    "\n",
    "def extract_name_from_resume(file_path, model_path=\"custom_name_ner\"):\n",
    "    nlp_model = spacy.load(model_path)\n",
    "\n",
    "    ext = os.path.splitext(file_path)[-1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        resume_text = extract_text_from_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        resume_text = extract_text_from_docx(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Only .pdf and .docx files are supported\")\n",
    "\n",
    "    doc = nlp_model(resume_text)\n",
    "    names = [ent.text for ent in doc.ents if ent.label_ == \"NAME\"]\n",
    "\n",
    "    return names[0] if names else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2Vwqo_pZF7T0",
    "outputId": "6481fd4f-3877-4285-b602-8be92ba11c96"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Bangalore,Karnataka India.PIN-560036EDAGOTTI HARIN...\" with entities \"[(36, 53, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n",
      "d:\\CybaemTech\\Projects\\name_extraction_model\\name_extraction_model\\Lib\\site-packages\\spacy\\training\\iob_utils.py:149: UserWarning: [W030] Some entities could not be aligned in the text \"Configuring VPN and troubleshooting VPN issues (Gl...\" with entities \"[(1310, 1324, 'NAME')]\". Use `spacy.training.offsets_to_biluo_tags(nlp.make_doc(text), entities)` to check the alignment. Misaligned entities ('-') will be ignored during training.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'NAME': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'speed': 8225.450532980349}\n",
      "  Precision: 1.0\n",
      "  Recall: 1.0\n",
      "  F-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 4. Evaluate the Model\n",
    "\n",
    "# Create a list of Example objects\n",
    "examples = []\n",
    "for text, annotations in TRAIN_DATA:\n",
    "    doc = nlp.make_doc(text)\n",
    "    example = Example.from_dict(doc, annotations)\n",
    "    examples.append(example)\n",
    "\n",
    "# Evaluate the model\n",
    "results = nlp.evaluate(examples) # Use the list of Example objects for evaluation\n",
    "print(\"Evaluation Results:\")\n",
    "print(results)\n",
    "\n",
    "# You can access specific metrics like:\n",
    "print(f\"  Precision: {results['token_p']}\")\n",
    "print(f\"  Recall: {results['token_r']}\")\n",
    "print(f\"  F-score: {results['token_f']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6541a96309a9455bae27fe3e06d57b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf,.docx', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40fae5f3d0394e8994b7975bacec4c8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "# Output widget for displaying results\n",
    "output = widgets.Output()\n",
    "\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept='.pdf,.docx',  # Accepted file types\n",
    "    multiple=False        # Single file upload\n",
    ")\n",
    "display(upload_widget)\n",
    "display(output)\n",
    "\n",
    "def handle_upload(change):\n",
    "    output.clear_output()  # Clear previous output\n",
    "    for file_info in upload_widget.value:\n",
    "        content = file_info['content']\n",
    "        name = file_info['name']\n",
    "        ext = os.path.splitext(name)[-1].lower()\n",
    "        temp_path = f'temp_uploaded{ext}'\n",
    "        with open(temp_path, 'wb') as f:\n",
    "            f.write(content)\n",
    "        # Now use your extraction function\n",
    "        extracted_name = extract_name_from_resume(temp_path, model_path=\"Name_extraction_model\")\n",
    "        with output:\n",
    "            if extracted_name:\n",
    "                print(f\"Extracted Name: {extracted_name}\")\n",
    "            else:\n",
    "                print(\"No name detected in the resume\")\n",
    "\n",
    "upload_widget.observe(handle_upload, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "k-f2n7V5L44N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['name_extraction_model.pkl']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(nlp, \"name_extraction_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved as name_extraction_model.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"model saved as name_extraction_model.pkl\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
